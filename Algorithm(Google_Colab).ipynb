{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyMy+Lou6QbR2XjB5alCE2pX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/07umar07/GlucoGuard/blob/main/Algorithm(Google_Colab).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ipovfF-YHuJ",
        "outputId": "c977025f-e76b-4ec0-90a7-2c03773913d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "   Dataset     Shape  Percentage\n",
            "0  X_train  (489, 6)   63.671875\n",
            "1    X_dev  (163, 6)   21.223958\n",
            "2   X_test  (116, 6)   15.104167\n",
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35     30.5  33.6   \n",
            "1            1       85             66             29     30.5  26.6   \n",
            "2            8      183             64             23     30.5  23.3   \n",
            "3            1       89             66             23     94.0  28.1   \n",
            "4            0      137             40             35    168.0  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n",
            "[322 167]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import imblearn as imb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "\n",
        "# Diabetes Prediction with Neural Network\n",
        "# Machine Learning Models\n",
        "# Date Created: October 28, 2024\n",
        "# By Umar Abdul Hakim Robbani\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 1. Data Featuring\n",
        "df = pd.read_csv('/content/drive/My Drive/Datasets/Diabetes_Datasets/diabetes.csv')\n",
        "# print(df.isnull().sum())\n",
        "# zero_counts = df.eq(0).sum()\n",
        "# print(zero_counts)\n",
        "\n",
        "df['Glucose'] = df['Glucose'].replace(0, np.median(df['Glucose']))\n",
        "df['BloodPressure'] = df['BloodPressure'].replace(0, np.median(df['BloodPressure']))\n",
        "df['SkinThickness'] = df['SkinThickness'].replace(0, np.median(df['SkinThickness']))\n",
        "df['Insulin'] = df['Insulin'].replace(0, np.median(df['Insulin']))\n",
        "df['BMI'] = df['BMI'].replace(0, np.median(df['BMI']))\n",
        "\n",
        "X = df.drop(['Outcome', 'SkinThickness', 'Insulin'], axis = 1).values\n",
        "y = df['Outcome'].values\n",
        "\n",
        "# Split Datasets\n",
        "X_train_dev, X_test, y_train_dev, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev, y_train_dev, test_size=0.25, random_state=42) # 0.176\n",
        "\n",
        "data_shapes = {\n",
        "  \"Dataset\": [\"X_train\", \"X_dev\", \"X_test\"],\n",
        "  \"Shape\": [X_train.shape, X_dev.shape, X_test.shape],\n",
        "  \"Percentage\": [100 / X.shape[0] * X_train.shape[0], 100 / X.shape[0] * X_dev.shape[0], 100 / X.shape[0] * X_test.shape[0]]\n",
        "}\n",
        "\n",
        "print(pd.DataFrame(data_shapes))\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# print(X_train.head())\n",
        "\n",
        "\n",
        "# X_train = X_train.values\n",
        "# X_test = X_test.values\n",
        "# y_train = y_train.values\n",
        "# y_test = y_test.values\n",
        "\n",
        "\n",
        "# Normalize the Data\n",
        "# Calculate mean and standard deviation for training data\n",
        "mean = np.mean(X_train, axis=0, keepdims= True)\n",
        "std = np.std(X_train, axis=0, keepdims= True)\n",
        "\n",
        "# Normalize training data\n",
        "X_train = (X_train - mean) / std\n",
        "\n",
        "# Normalize dev data using training data's mean and std\n",
        "X_dev = (X_dev - mean) / std\n",
        "\n",
        "# Normalize test data using training data's mean and std\n",
        "X_test = (X_test - mean) / std\n",
        "\n",
        "# 1.1. Checking whether the data is imbalanced or not\n",
        "print(np.bincount(y_train))\n",
        "ROS = imb.over_sampling.RandomOverSampler()\n",
        "X_train, y_train = ROS.fit_resample(X_train, y_train)\n",
        "# X_train = X_train\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import L2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "# from initialization import X_train, X_dev, X_test, y_train, y_dev, y_test\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
        "\n",
        "# Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Neural Network Architecture\n",
        "model = Sequential(\n",
        "  [\n",
        "    Input(shape=(6,)),\n",
        "    Dense(units = 64, activation = 'relu', kernel_regularizer = L2(0.8)), #L1\n",
        "    BatchNormalization(),\n",
        "    # Dense(units = 64, activation = 'relu', kernel_regularizer = L2(0.8)), #L2\n",
        "    # BatchNormalization(),\n",
        "    Dense(units = 32, activation = 'relu', kernel_regularizer = L2(0.8)), #L3\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(units = 32, activation = 'relu', kernel_regularizer = L2(0.8)), #L4\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.25),\n",
        "    Dense(units = 32, activation = 'relu', kernel_regularizer = L2(0.8)), #L5\n",
        "    # BatchNormalization(),\n",
        "    # Dense(units = 256, activation = 'relu', kernel_regularizer = L2(0.02)),\n",
        "    Dense(units = 32, activation = 'relu', kernel_regularizer = L2(0.8)), #L6\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3), #'\n",
        "    Dense(units = 64, activation = 'relu', kernel_regularizer = L2(0.8)), #L7\n",
        "    # # BatchNormalization(),\n",
        "    # Dropout(0.3),\n",
        "    # Dense(units = 315, activation = 'relu', kernel_regularizer = L2(0.8)), #L8\n",
        "    # BatchNormalization(),\n",
        "    # Dense(units = 256, activation = 'relu', kernel_regularizer = L2(0.3)), #L9\n",
        "    Dense(units = 1, activation = 'sigmoid'),\n",
        "  ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "  loss = tf.keras.losses.binary_crossentropy,\n",
        "  optimizer = tf.keras.optimizers.Adam(0.0001), #1, 3, 5, 7\n",
        "  metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "  X_train, y_train,\n",
        "  epochs = 100,\n",
        "  batch_size = 16,\n",
        "  validation_data = (X_dev, y_dev),\n",
        "  callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_train, y_train)\n",
        "print(f\"Train Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_dev, y_dev)\n",
        "print(f\"Dev Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "model.save('/content/drive/My Drive/Ml_Models_tensorflow/diabetes_det_gd2_51.keras') #gd2 (good), gd2_1 (good)\n",
        "# gd2_2 (Great), 2_3 (Not like before but great), 2_31 (stil 2_2 greater), 2_32 (89-77-76)\n",
        "# 2_4 (GREATEST, 90/79/78), 2_41 (86/78/77), 2_5 (84/78/78), 2_51"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "sEuiiNMaZo6_",
        "outputId": "c00c8158-8d6d-4d71-cebd-9b1ecea2d9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f6983350de4d>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m history = model.fit(\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m   \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    }
  ]
}